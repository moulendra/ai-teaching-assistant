# ğŸ“ AI-Powered Adaptive Teaching Assistant

An AI-driven teaching assistant that understands student queries using NLP + Transformer embeddings and adapts learning paths using reinforcement-inspired personalization logic.

---

## ğŸ“Œ Problem Statement

This system implements two core capabilities:

### 1ï¸âƒ£ Student Query Understanding (Q1)

Given a natural language student query, the system classifies:

- **Intent Type** â†’ Explanation / Example / Doubt Clarification / Revision  
- **Topic** â†’ e.g., Backpropagation, Gradient Descent, Neural Networks  
- **Difficulty Level** â†’ Beginner / Intermediate / Advanced  

Example:

Input:
"I don't understand backpropagation."

Output:
```json
{
  "intent": "Explanation",
  "topic": "Backpropagation",
  "difficulty_level": "Beginner"
}
```

---

### 2ï¸âƒ£ Adaptive Learning Path Recommendation (Q2)

Based on student performance and behavior, the system recommends:

- Next topic to study  
- Whether revision is required  
- Difficulty adjustment (Increase / Decrease / Same)

Example:

```json
{
  "next_topic": "Backpropagation",
  "action": "Revision",
  "difficulty_adjustment": "Decrease"
}
```

---

# ğŸ§  System Architecture

```
Student Query
     â†“
Sentence Embeddings (MiniLM / SBERT)
     â†“
ML Classifiers (Intent + Difficulty)
     â†“
Topic Detection
     â†“
LLM Prompt Refinement (Optional)
     â†“
Adaptive Engine (RL-inspired logic)
     â†“
Personalized Recommendation
```

---

# ğŸ” Q1: Student Query Understanding

## ğŸ§© Techniques Used

### 1. Sentence Embeddings
- Model: sentence-transformers/all-MiniLM-L6-v2
- Converts queries into dense semantic vectors
- Captures contextual meaning beyond keywords

### 2. Intent Classification
- ML Model: Logistic Regression
- Input: Sentence embeddings
- Output: Intent category

### 3. Difficulty Classification
- ML Model: Logistic Regression
- Predicts Beginner / Intermediate / Advanced

### 4. Topic Classification
- Lightweight topic model using trained classifier

### 5. LLM Refinement (Prompt-Based)
- LLM used to refine ambiguous cases
- Improves semantic consistency
- Used for interpretation, not raw prediction

---

## ğŸ“Š Q1 Model Performance

- Intent Classification Accuracy: ~100% (Synthetic Balanced Dataset)
- Difficulty Classification Accuracy: ~32â€“40% (Multiclass realistic distribution)

Classification reports available during training phase.

---

# ğŸ” Q2: Adaptive Learning Recommendation

## ğŸ¯ Inputs

- Quiz score
- Number of attempts
- Time spent on topic
- Mastery score
- Current topic

---

## âš™ï¸ Personalization Logic

The adaptive engine combines:

### 1ï¸âƒ£ Rule-Based Layer
- Low score â†’ Recommend revision
- High mastery â†’ Increase difficulty
- Many attempts + low score â†’ Decrease difficulty

### 2ï¸âƒ£ Reinforcement-Inspired Policy

State:
(score, mastery, attempts, time_spent)

Action:
(Next Topic, Revision/Advance, Difficulty Change)

The policy optimizes:
- Learning stability
- Progressive complexity
- Reduced frustration

### 3ï¸âƒ£ Knowledge Tracing (Basic)
Mastery score updates simulate student knowledge progression.

---

# ğŸ“‚ Project Structure

```
ai-teaching-assistant/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ train_models.py
â”œâ”€â”€ evaluate_q2.py
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ synthetic_queries.csv
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ intent_classifier.pkl
â”‚   â””â”€â”€ difficulty_classifier.pkl
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ embeddings.py
    â”œâ”€â”€ intent_model.py
    â”œâ”€â”€ difficulty_model.py
    â”œâ”€â”€ topic_model.py
    â”œâ”€â”€ knowledge_tracing.py
    â”œâ”€â”€ reinforcement_learning.py
    â”œâ”€â”€ adaptive_engine.py
    â””â”€â”€ llm_refinement.py
```

---

# ğŸ“Š Dataset Information

Since no dataset was provided, synthetic data was generated.

## Synthetic Data Generation

- Generated structured queries per topic
- Balanced intent distribution
- Difficulty labels assigned programmatically
- Dataset size < 50MB (as per constraints)

### Assumptions:
- Queries follow academic style
- Difficulty correlates with conceptual depth
- Students behave rationally based on performance

### Limitations:
- Synthetic data lacks real-world noise
- Reinforcement logic is simplified (not full Q-learning)
- Limited topic diversity

---

# ğŸš€ Setup Instructions

## 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/YOUR_USERNAME/ai-teaching-assistant.git
cd ai-teaching-assistant
```

---

## 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
venv\Scripts\activate
```

---

## 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## 4ï¸âƒ£ Train Models

```bash
python train_models.py
```

---

## 5ï¸âƒ£ Run Application

```bash
uvicorn app:app --reload
```

Open in browser:

http://127.0.0.1:8000/docs

---

# ğŸ§ª API Endpoints

## Q1 â€” Query Analysis

POST `/analyze`

Example:
```json
{
  "query": "I don't understand backpropagation"
}
```

---

## Q2 â€” Learning Recommendation

POST `/recommend`

Example:
```json
{
  "mastery": 0.3,
  "score": 40,
  "attempts": 3,
  "time_spent": 120,
  "current_topic": "Backpropagation"
}
```

---

# ğŸ“ˆ Evaluation

### Q1
- Accuracy
- Precision / Recall / F1-score
- Classification report

### Q2
- Policy consistency
- Logical adaptation
- Scenario testing

Run:
```
python evaluate_q2.py
```

---

# ğŸ¯ Alignment with Evaluation Criteria

| Criteria | Implementation |
|----------|---------------|
| ML Algorithm Depth | Transformer embeddings + classifiers |
| LLM Usage Quality | Prompt-based refinement |
| Personalization Logic | RL-inspired adaptive engine |
| System Design | Modular architecture |
| Innovation | Hybrid ML + policy-based adaptation |

---

# ğŸ¬ Demo Video Outline (3â€“5 Minutes)

1. Explain architecture
2. Show Q1 classification
3. Show Q2 recommendation
4. Explain personalization logic
5. Explain model decisions

---

# ğŸ”® Future Improvements

- Real student dataset integration
- True reinforcement learning (Q-learning / DQN)
- Knowledge graph for topic relationships
- Student profiling memory
- Performance dashboard

---

# ğŸ‘¨â€ğŸ’» Author

Mouli P  
AI Teaching Assistant Project

---

# ğŸ“Œ Conclusion

This system demonstrates a complete pipeline for:

- NLP-based query understanding  
- ML-driven intent and difficulty classification  
- Reinforcement-inspired adaptive learning  
- Modular and scalable architecture  

The design balances interpretability, ML depth, and practical personalization.
